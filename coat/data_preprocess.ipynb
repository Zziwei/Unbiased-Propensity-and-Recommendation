{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_matrix = np.loadtxt('./train.ascii')\n",
    "userId = np.where(raw_matrix > 0)[0]\n",
    "itemId = np.where(raw_matrix > 0)[1]\n",
    "rating = raw_matrix[np.where(raw_matrix > 0)]\n",
    "train_df = pd.DataFrame({'userId': userId, 'itemId': itemId, 'rating': rating})\n",
    "raw_matrix = np.loadtxt('./test.ascii')\n",
    "userId = np.where(raw_matrix > 0)[0]\n",
    "itemId = np.where(raw_matrix > 0)[1]\n",
    "rating = raw_matrix[np.where(raw_matrix > 0)]\n",
    "test_df = pd.DataFrame({'userId': userId, 'itemId': itemId, 'rating': rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 300\n",
      "train user num = 290\n",
      "test user num = 290\n"
     ]
    }
   ],
   "source": [
    "item_set = set(train_df['itemId'].unique())\n",
    "train_user_set = set(train_df['userId'].unique())\n",
    "test_user_set = set(test_df['userId'].unique())\n",
    "print('item num = ' + str(len(item_set)))\n",
    "print('train user num = ' + str(len(train_user_set)))\n",
    "print('test user num = ' + str(len(test_user_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6960"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''rating equal or larger than 4 as positive feedback'''\n",
    "\n",
    "train_df.drop(train_df[train_df['rating'] <= 3].index, inplace=True)\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "train_df.drop(columns=['rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4640"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_list = train_df['itemId'].unique()\n",
    "test_df = test_df.loc[test_df[test_df['itemId'].isin(train_item_list)].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4407"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''rating equal or larger than 4 as positive feedback'''\n",
    "\n",
    "test_df.loc[test_df['rating'] <= 3, 'rating'] = 0\n",
    "test_df.loc[test_df['rating'] > 3, 'rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 284\n",
      "train user num = 290\n",
      "test user num = 290\n"
     ]
    }
   ],
   "source": [
    "print('item num = ' + str(len(train_df['itemId'].unique())))\n",
    "print('train user num = ' + str(len(train_df['userId'].unique())))\n",
    "print('test user num = ' + str(len(test_df['userId'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''in test set, only keep users who have at least one positive and one \n",
    "negative feedback, and have at least two positive feedback in training set'''\n",
    "\n",
    "user_list = []\n",
    "for u in test_user_set:\n",
    "    test_num = len(test_df.loc[test_df['userId'] == u])\n",
    "    pos_num = np.sum(test_df.loc[test_df['userId'] == u, 'rating'])\n",
    "    train_num = len(train_df.loc[train_df['userId'] == u])\n",
    "    if pos_num >= 1 and pos_num < test_num and train_num >= 1:\n",
    "        user_list.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(test_df[~test_df['userId'].isin(user_list)].index, inplace=True)\n",
    "test_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''get the user old id->new id dict'''\n",
    "\n",
    "all_user_list = train_df['userId'].unique()\n",
    "all_item_list = train_df['itemId'].unique()\n",
    "j = 0\n",
    "user_old2new_id_dict = dict()\n",
    "for u in all_user_list:\n",
    "    if not u in user_old2new_id_dict:\n",
    "        user_old2new_id_dict[u] = j\n",
    "        j += 1\n",
    "        \n",
    "j = 0\n",
    "item_old2new_id_dict = dict()\n",
    "for i in all_item_list:\n",
    "    if not i in item_old2new_id_dict:\n",
    "        item_old2new_id_dict[i] = j\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''reindex users and items in training and test set'''\n",
    "\n",
    "for i in range(len(train_df)):\n",
    "    train_df.at[i, 'userId'] = user_old2new_id_dict[train_df.at[i, 'userId']]\n",
    "    train_df.at[i, 'itemId'] = item_old2new_id_dict[train_df.at[i, 'itemId']]\n",
    "train_user_list = train_df['userId'].unique()\n",
    "train_item_list = train_df['itemId'].unique()\n",
    "for i in range(len(test_df)):\n",
    "    test_df.at[i, 'userId'] = user_old2new_id_dict[test_df.at[i, 'userId']]\n",
    "    test_df.at[i, 'itemId'] = item_old2new_id_dict[test_df.at[i, 'itemId']]\n",
    "test_user_list = test_df['userId'].unique()\n",
    "test_item_list = test_df['itemId'].unique()\n",
    "\n",
    "all_user_list = train_df['userId'].unique()\n",
    "all_item_list = train_df['itemId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 284\n",
      "train user num = 290\n",
      "test user num = 237\n"
     ]
    }
   ],
   "source": [
    "print('item num = ' + str(len(train_df['itemId'].unique())))\n",
    "print('train user num = ' + str(len(train_df['userId'].unique())))\n",
    "print('test user num = ' + str(len(test_df['userId'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''further split 10% from training data as validation set'''\n",
    "\n",
    "train_ratio = 0.9\n",
    "vali_ratio = 0.1\n",
    "\n",
    "vali_size = int(vali_ratio * len(train_df))\n",
    "vali_idx = np.random.choice(np.arange(len(train_df)), \n",
    "                            vali_size, replace=False).tolist()\n",
    "vali_df = train_df.copy()\n",
    "vali_df = vali_df.loc[vali_idx]\n",
    "\n",
    "train_df.drop(vali_idx, axis=0, inplace=True)\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "vali_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002306945118989801"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vali_df) * 1.0 / (len(all_user_list) * len(all_item_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''compute the popularity of items in training set'''\n",
    "item_pop = np.array(train_df['itemId'].value_counts())\n",
    "item_pop_id = np.array(train_df['itemId'].value_counts().index)\n",
    "item_pop_list = [0] * len(all_item_list)\n",
    "for i in range(len(item_pop_id)):\n",
    "    item_pop_list[item_pop_id[i]] = item_pop[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''compute the popularity of users in training set'''\n",
    "user_pop = np.array(train_df['userId'].value_counts())\n",
    "user_pop_id = np.array(train_df['userId'].value_counts().index)\n",
    "user_pop_list = [0] * len(all_user_list)\n",
    "for i in range(len(user_pop_id)):\n",
    "    user_pop_list[user_pop_id[i]] = user_pop[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''generate list of items users like in train and vali sets for each user'''\n",
    "\n",
    "user_train_like = []\n",
    "user_vali_like = []  \n",
    "\n",
    "train_array = train_df[['userId', 'itemId']].values\n",
    "vali_array = vali_df[['userId', 'itemId']].values\n",
    "\n",
    "for u in all_user_list:\n",
    "    train_like = (train_array[list(np.where(train_array[:, 0] == u)[0]), \n",
    "                              1]).astype(int)\n",
    "    vali_like = (vali_array[list(np.where(vali_array[:, 0] == u)[0]), \n",
    "                            1]).astype(int)\n",
    "    user_train_like.append(train_like)\n",
    "    user_vali_like.append(vali_like)\n",
    "    \n",
    "# np.save('./user_train_like.npy', np.array(user_train_like))\n",
    "# np.save('./user_vali_like.npy', np.array(user_vali_like))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv('./train_df.csv', index=False)\n",
    "# vali_df.to_csv('./vali_df.csv', index=False)\n",
    "# test_df.to_csv('./test_df.csv', index=False)\n",
    "\n",
    "# np.save('./item_pop.npy', np.array(item_pop_list))\n",
    "# np.save('./user_pop.npy', np.array(user_pop_list))\n",
    "\n",
    "# with open('./info.pkl', 'wb') as f:\n",
    "#     pickle.dump({'num_user': len(all_user_list), 'num_item': len(all_item_list)}, f)\n",
    "    \n",
    "# with open('./user_old2new_id_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(user_old2new_id_dict, f)\n",
    "# with open('./item_old2new_id_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(item_old2new_id_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''generate list of items users interact and like in test set for each user'''\n",
    "\n",
    "user_list = test_df['userId'].unique()\n",
    "\n",
    "user_test_interact = []\n",
    "user_test_like = []  \n",
    "\n",
    "test_array = test_df[['userId', 'itemId', 'rating']].values\n",
    "\n",
    "for u in user_list:\n",
    "    test_interact = (test_array[list(np.where(test_array[:, 0] == u)[0]),\n",
    "                                1]).astype(int)\n",
    "    tmp = (test_array[list(np.where(test_array[:, 0] == u)[0]), 2]).astype(int)\n",
    "    test_like = np.where(tmp == 1)[0]\n",
    "    user_test_interact.append(test_interact)\n",
    "    user_test_like.append(test_like)\n",
    "    \n",
    "# np.save('./user_test_list.npy', np.array(user_list))\n",
    "# np.save('./user_test_interact.npy', np.array(user_test_interact))\n",
    "# np.save('./user_test_like.npy', np.array(user_test_like))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i in range(len(user_list)):\n",
    "    like = user_test_like[i]\n",
    "    tmp.append(len(like) / 10.)\n",
    "np.mean(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i in range(len(user_train_like)):\n",
    "    like = user_train_like[i]\n",
    "    tmp.append(len(like) / 1000.)\n",
    "np.mean(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.3653333333333333 / 0.0059137931034482765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
